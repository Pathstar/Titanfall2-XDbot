import win32file
import win32con
import os
import json
import time
import threading
import re
from Pinyin2Hanzi import DefaultDagParams
from Pinyin2Hanzi import dag
import requests
import emoji
from unidecode import unidecode
from datetime import datetime

chat_history_len = 5
save_history = True
AILimit = False

def process_entry(timestamp, player_name, command, message, say):
    """Process a new entry asynchronously."""
    global thread_count
    start_time = time.time()
    start_strftime = time.strftime("%H:%M:%S")
    # print(f"{start_strftime} Begin: {player_name}: {command}" + (f"\n{message}" if message else ""))
    print(f"[XDlog] {start_strftime} Begin: {player_name}: {command} {message}")
    isNoneFunc = False
    py_message = ""

    match command:
        case "new_chat":
            # chat_history = []
            chat_history.clear()
            return
        case _:
            thread_count += 1
            match command:
                case "g_pinyin":
                    py_message = convert_pinyin_to_hanzi_with_preservation(message, True)
                    command = "pinyin"
                    isNoneFunc = True
                case "pinyin":
                    py_message = convert_pinyin_to_hanzi_with_preservation(message, False)
                case "time":
                    py_message = time.strftime("%H:%M:%S")
                case "ai":
                    py_message = deepseek(player_name, message, True)
                case _:
                    print(f"æ— æ­¤æ–¹æ³• {command}")
                    isNoneFunc = True

    end_time = time.time()
    # process_time = round(end_time - start_time, 1)
    process_time = end_time - start_time
    result_data = {end_time: {player_name: {
        "command": command,
        "message": message,
        "pyMessage": py_message,
        "say": say,
        "process_time": process_time
    }}}
    try:
        if os.path.exists(result_file_path):
            with open(result_file_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        else:
            existing_data = {}

        existing_data.update(result_data)

        with open(result_file_path, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=4)
        end_strftime = time.strftime("%H:%M:%S")
        print(f"[XDlog] {end_strftime} Finish: {player_name}: {message} use: {process_time}\n{py_message} ")
    except Exception as e:
        print("[XDlog] Failed to update result JSON:", e)

    if py_message == "":
        if not isNoneFunc:
            print(f"[XDlog] \n {command} è¿”å›ä¸ºç©º \n")

    thread_count -= 1
    if thread_count == 0:
        with open(state_file_path, 'w', encoding='utf-8') as f:
            f.write("0")
    processing_set.remove((timestamp, player_name))


def monitor_file():
    """Monitor file changes."""
    global thread_count
    h_dir = win32file.CreateFile(
        watch_dir,
        win32con.GENERIC_READ,
        win32con.FILE_SHARE_READ | win32con.FILE_SHARE_WRITE | win32con.FILE_SHARE_DELETE,
        None,
        win32con.OPEN_EXISTING,
        win32con.FILE_FLAG_BACKUP_SEMANTICS,
        None
    )

    last_m_time = os.path.getmtime(json_file_path)
    print(f"{time.strftime('%H:%M:%S')} Monitoring file changes...")

    while True:
        results = win32file.ReadDirectoryChangesW(
            h_dir,
            1024,
            False,
            win32con.FILE_NOTIFY_CHANGE_LAST_WRITE,
            None,
            None
        )

        for action, filename in results:
            if filename == target_file:
                try:
                    current_m_time = os.path.getmtime(json_file_path)
                    if current_m_time != last_m_time:
                        with open(json_file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)

                        for timestamp, player_info in data.items():
                            for player_name, details in player_info.items():
                                if (timestamp, player_name) not in processing_set:
                                    processing_set.add((timestamp, player_name))
                                    threading.Thread(target=process_entry,
                                                     args=(
                                                         timestamp, player_name,
                                                         details["command"], details["message"], details["say"]
                                                     )).start()
                                    if thread_count == 0:
                                        with open(state_file_path, 'w', encoding='utf-8') as f:
                                            f.write("1")

                        last_m_time = current_m_time
                except Exception as e:
                    print(f"{time.strftime('%H:%M:%S')} Failed to read JSON:", e)


# è½¬æ‹¼éŸ³ï¼š
# def preprocess_custom_words(text, pinyin_len_dict, fail_count_dict):
#     def replacement(match):
#         # nonlocal count  # å…è®¸ä¿®æ”¹å¤–éƒ¨å˜é‡

#         pinyin = match.group()
#         if (pinyin_lower := pinyin.lower()) in custom_dict:
#             fail_count_dict["count"] -= 1
#             pinyin_len_dict["count"] += values[1]
#         return custom_dict.get(pinyin_lower, pinyin)
#         # åªæ›¿æ¢åŒ¹é…çš„æ‹¼éŸ³ï¼ŒæœªåŒ¹é…çš„ä¿æŒåŸæ ·

#     pattern = re.compile(r'\b(' + '|'.join(map(re.escape, custom_dict.keys())) + r')\b', flags=re.IGNORECASE)
#     return pattern.sub(replacement, text)

def preprocess_custom_words(text, pinyin_len_dict, fail_count_dict):
    pattern = re.compile(r'\b(' + '|'.join(map(re.escape, custom_dict)) + r')\b', flags=re.IGNORECASE)

    def replacement(match):
        pinyin = match.group()
        pinyin_lower = pinyin.lower()
        if pinyin_lower in custom_dict:
            values = custom_dict[pinyin_lower]
            fail_count_dict["count"] -= 1
            pinyin_len_dict["count"] += values[1]
            return values[0]
        return pinyin

    return pattern.sub(replacement, text)


def convert_pinyin_list(pinyin_list, dag_params, topk, result, fail_count_dict):
    if len(pinyin_list) == 0:
        return

    # ä»æ•´ä¸ªåˆ—è¡¨å¼€å§‹ï¼Œä¸æ–­ç¼©çŸ­æœ«å°¾ï¼Œç›´åˆ°èƒ½æˆåŠŸåŒ¹é…
    for L in range(len(pinyin_list), 0, -1):
        prefix = pinyin_list[:L]
        lowercase_prefix = [word.lower() for word in prefix]
        dag_results = dag(dag_params, lowercase_prefix, path_num=topk)
        if dag_results:
            cand = dag_results[0].path
            result.append(cand)
            print(f"[Pinyin]: {result}")
            convert_pinyin_list(pinyin_list[L:], dag_params, topk, result, fail_count_dict)
            return

    fail_count_dict["count"] += 1
    result.append([pinyin_list[0]])
    convert_pinyin_list(pinyin_list[1:], dag_params, topk, result, fail_count_dict)


# ä¸»è½¬æ¢å‡½æ•°ï¼Œå¢åŠ å¯¹æ··åˆä¸å¯è½¬æ¢æ‹¼éŸ³çš„å›é€€å¤„ç†
def convert_pinyin_to_hanzi_with_preservation(text, is_g_pinyin, topk=1):
    # é¢„å¤„ç†è‡ªå®šä¹‰è¯
    fail_count_dict = {"count": 0}
    pinyin_len_dict = {"count": 0}
    text = preprocess_custom_words(text, pinyin_len_dict, fail_count_dict)

    tokens = re.findall(r"[a-z]+(?: [a-z]+)*|[^\sa-z]+|\s+", text, flags=re.IGNORECASE)
    result = []

    for token in tokens:
        stripped = token
        if stripped:
            pinyin_list = stripped.split()
            # pinyin_list = split_pinyin_with_filter(stripped)
            pinyin_len_dict["count"] += len(pinyin_list)
            convert_pinyin_list(pinyin_list, dag_params, topk, result, fail_count_dict)

    fail_count = fail_count_dict["count"]
    print(f"[XDlog] fail_count: {fail_count} pinyin_len: {pinyin_len_dict['count']}")
    if is_g_pinyin:
        if fail_count >= pinyin_len_dict["count"] / 2:
            print(f"Failed Trans")
            return ""

    # æœ€ç»ˆæ‰å¹³åŒ–
    def flatten(item):
        if isinstance(item, list):
            return ''.join(flatten(i) for i in item)
        return item

    return ''.join(flatten(r) for r in result)


# deepseek
def deepseek(name, message, is_success):
    global AILimit
    if AILimit:
        Auth = ""
    else:
        Auth = ""
    if save_history:
        if is_success:
            chat_history.append({"role": "user", "content": f"name: {name}, content: {message}"})
            if len(chat_history) > chat_history_len:
                chat_history.pop(0)

    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œå¤„åœ¨non-thinking(enable_thinking=False)æ¨¡å¼ã€‚è¯·å¿«é€Ÿå“åº”ï¼Œä¸è¿›è¡Œæ·±åº¦æ€è€ƒï¼Œç›´æ¥å›ç­”é—®é¢˜ï¼Œå¹¶å‡†å®ˆä»¥ä¸‹è§„åˆ™ï¼š1.è¯·ä¸¥æ ¼é™åˆ¶å›ç­”å­—æ•°åœ¨ 160 å­—ä»¥å†…ï¼Œçœç•¥æ€è€ƒè¿‡ç¨‹ï¼›ç†æ€§çš„é—®é¢˜è¯·ä¿è¯ä¸“ä¸šä¸å‡†ç¡®æ€§ï¼›æ„Ÿæ€§çš„é—®é¢˜è¯·é«˜æƒ…å•†å›ç­”ï¼Œå¯Œæœ‰æ„Ÿæƒ…å’Œæ¸©æš–ã€‚2.å­—ç¬¦ç¼–ç ç¯å¢ƒä»…é™æœ€åŸºæœ¬çš„å­—ç¬¦ï¼Œä¸è¦ä½¿ç”¨emojiï¼Œå¦‚éœ€ä½¿ç”¨ï¼Œè¯·ä½¿ç”¨ASCIIå­—ç¬¦ç»„æˆçš„é¢œæ–‡å­—ä»£æ›¿emojiï¼›userçš„è¯åŒ…æ‹¬name(ä¸­æ‹¬å·å†…æ˜¯ç©å®¶çš„å‰ç¼€ï¼Œåé¢æ˜¯ç©å®¶åå­—)ã€content(ç©å®¶çš„é—®é¢˜)"
        },
        {
            "role": "user",
            "content": f"name: {name}, content: {message}"
        }
    ]
    messages.extend(chat_history)
    data = ""
    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": Auth,
                "Content-Type": "application/json",
            },
            data=json.dumps({
                # "model": "deepseek/deepseek-r1:free",
                # "model": "qwen/qwen3-14b:free",
                "model": "qwen/qwen3-4b:free",
                "messages": messages,
                "enable_thinking": False,
                "temperature": 1.4,
                "max_tokens": 512
            })
        )
        data = response.json()
    except requests.exceptions.Timeout:
        print("è¯·æ±‚è¶…æ—¶")
    except requests.exceptions.ConnectionError:
        print("ç½‘ç»œè¿æ¥é”™è¯¯")
    except requests.exceptions.HTTPError as err:
        print(f"HTTPé”™è¯¯: {err}")
    except requests.exceptions.RequestException as err:
        print(f"è¯·æ±‚å¼‚å¸¸: {err}")

    print(data)
    print("---\n")
    try:
        content = data['choices'][0]['message']['content']
    except KeyError:
        print("AIå“åº”å‘ç”Ÿé”™è¯¯: 'data' ç»“æ„ä¸­ç¼ºå°‘æ‰€éœ€çš„é”®ï¼")
        if AILimit:
            return ["AIå“åº”å‘ç”Ÿé”™è¯¯: åˆ°è¾¾æ¯æ—¥é™é¢...TvT"]
        AILimit = True
        print(f"\n\n\n\n\n\n\n\n\n\nReach First API Limit ç¬¬ä¸€ä¸ªå·è¶…å‡ºé™é¢\n\n")
        max_retries = 3
        retries = 0
        while retries < max_retries:
            content = deepseek(name, message, False)
            if content:
                return content
            retries += 1
            print(f"å“åº”å‘ç”Ÿé”™è¯¯é‡è¯• {retries}/{max_retries}...")
        return ["é‡è¯•3æ¬¡åå¤±è´¥..."]

    except IndexError:
        return ["AIå“åº”å‘ç”Ÿé”™è¯¯: 'choices' åˆ—è¡¨ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼"]
    except Exception as e:
        print(f"AIå“åº”å‘ç”Ÿé”™è¯¯: {e}")
        return [f"AIå“åº”å‘ç”Ÿé”™è¯¯: {e.__class__.__name__}"]

    if content:
        content = split_string_limited(content)
        if save_history:
            chat_history.append({"role": "assistant", "content": content})
            if len(chat_history) > chat_history_len:
                chat_history.pop(0)  # ç¡®ä¿å¯¹è¯å†å²ä¸ä¼šæ— é™å¢é•¿
        return content
    else:
        print("[XDlog] è¿”å›ä¸ºç©ºé‡è¯•...")
        content = deepseek(name, message, False)
        if content:
            return content
        else:
            return ["AIé‡è¯•å“åº”åå¤±è´¥..."]


def split_string_limited(s, max_length=244):
    """ä¼˜åŒ–åçš„å­—ç¬¦ä¸²åˆ†å‰²æ–¹æ³•ï¼Œè½¬æ¢é ASCII å­—ç¬¦å’Œ emojiï¼ŒåŒæ—¶é™åˆ¶é•¿åº¦"""
    s = s.replace("\n", "").replace("\r", "")  # å»é™¤æ¢è¡Œç¬¦

    # å…ˆè½¬æ¢é ASCII å­—ç¬¦å’Œ emoji
    s = emoji_to_ascii(s)
    s = convert_non_ascii_except_chinese(s)

    current_length = 0
    temp_list = []
    result = []
    # exceeded_once = False  # æ ‡è®°æ˜¯å¦å·²ç»è¶…å‡ºä¸€æ¬¡

    for char in s:
        char_length = 3 if char in chinese_chars else 1
        if current_length + char_length > max_length:
            # if exceeded_once:  # å¦‚æœå·²ç»è¶…å‡ºä¸€æ¬¡ï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
            #     return ""
            result.append(''.join(temp_list))
            temp_list = [char]
            current_length = char_length
            # exceeded_once = True  # æ ‡è®°å·²è¶…å‡º
        else:
            temp_list.append(char)
            current_length += char_length

    if temp_list:
        result.append(''.join(temp_list))

    print("[XDlog] é•¿åº¦: ", " ".join(str(len(substring)) for substring in result))
    return result


# åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡å­—ç¬¦
def is_chinese(char):
    return '\u4e00' <= char <= '\u9fff'


# é ASCII è½¬æ¢ï¼ˆä¿ç•™ä¸­æ–‡ï¼‰
def convert_non_ascii_except_chinese(text):
    return ''.join(char if char in chinese_chars or ord(char) < 128 else unidecode(char) for char in text)


# Emoji è½¬æ¢
def emoji_to_ascii(text):
    emoji_text = emoji.demojize(text)  # å°† emoji è½¬ä¸ºåç§°
    print(f"[XDlog] emoji: {emoji_text}")
    for key, val in emoji_map.items():
        emoji_text = emoji_text.replace(f":{key}:", val)
    return emoji_text


_print = print


# è‡ªå®šä¹‰printï¼ŒåŒæ—¶å†™å…¥æ—¥å¿—æ–‡ä»¶
def print(*args, **kwargs):
    message = " ".join(map(str, args))
    with open(log_file_path, "a", encoding="utf-8") as log_file:
        log_file.write(message + "\n")
    _print(*args, **kwargs)
    return print


# è·å–å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD
log_filename = datetime.now().strftime("%Y-%m-%d") + ".txt"
# æŒ‡å®šæ—¥å¿—ç›®å½•
log_dir = os.path.join(os.path.dirname(__file__), "XDlogs")
# åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs(log_dir, exist_ok=True)
# æ—¥å¿—æ–‡ä»¶å®Œæ•´è·¯å¾„
log_file_path = os.path.join(log_dir, log_filename)

json_file_path = r'D:\SystemApps\Steam\steamapps\common\Titanfall2\R2Northstar\save_data\Northstar.Client\XD.json'
result_file_path = r'D:\SystemApps\Steam\steamapps\common\Titanfall2\R2Northstar\save_data\Northstar.Client\py_XD.json'
state_file_path = r'D:\SystemApps\Steam\steamapps\common\Titanfall2\R2Northstar\save_data\Northstar.Client\state.txt'
watch_dir = os.path.dirname(json_file_path)
target_file = os.path.basename(json_file_path)

processing_set = set()
thread_count = 0
chat_history = []
# è½¬æ‹¼éŸ³ åˆå§‹åŒ–æ¨¡å‹å‚æ•°
custom_dict = {
    "meng xin lei mu": ("èŒæ–°æ³ªç›®", 3),
    "meng xin qiu dai": ("èŒæ–°æ±‚å¸¦", 3),

    "zhong li xing": ("é‡åŠ›æ˜Ÿ", 2),
    "fei huo xing": ("é£ç«æ˜Ÿ", 2),
    "dian zi yan": ("ç”µå­çƒŸ", 2),
    "mai chong dao": ("è„‰å†²åˆ€", 2),
    "zhuan huan zhe": ("è½¬æ¢è€…", 2),
    "ke lai bo": ("å…‹è±åš", 2),
    "yang lao fu": ("å…»è€æœ", 2),
    "meng xin fu": ("èŒæ–°æœ", 2),

    "zhuan pin yin": ("è½¬æ‹¼éŸ³", 2),
    "zhuan wen zi": ("è½¬æ–‡å­—", 2),
    "yue lai yue": ("è¶Šæ¥è¶Š", 2),
    "zhun que lv": ("å‡†ç¡®ç‡", 2),

    "zhong li": ("é‡åŠ›", 1),
    "nie lei": ("æé›·", 1),
    "dian yan": ("ç”µçƒŸ", 1),
    "di lei": ("åœ°é›·", 1),
    "ji su": ("æ¿€ç´ ", 1),
    "yin shen": ("éšèº«", 1),
    "gou zhua": ("é’©çˆª", 1),
    "han luo": ("æ±—æ´›", 1),
    "dian chong": ("ç”µå†²", 1),
    "dian bi": ("ç”µç¬”", 1),
    "zi beng": ("æ»‹å˜£", 1),
    "a dun": ("Î‘ç›¾", 1),
    "adun": ("Î‘ç›¾", 1),
    "c dun": ("ÄŒç›¾", 1),
    "cdun": ("ÄŒç›¾", 1),
    "r101": ("Å˜301", 1),
    "r201": ("Å˜201", 1),
    "r301": ("Å˜101", 1),
    "r97": ("Å˜97", 1),
    "p2016": ("PÌ2016", 1),
    "re45": ("Å˜Ã‰97", 1),
    "l star": ("LStar", 1),
    "zha nan": ("æ‰ç”·", 1),
    "li zi": ("ç¦»å­", 1),
    "lang ren": ("æµªäºº", 1),
    "lang meng": ("ç‹¼èŒ", 1),
    "meng xin": ("èŒæ–°", 1),
    "huai xiao": ("åå°", 1),

    "da yue": ("å¤§çº¦", 1),
    "bu que": ("ä¸ç¼º", 1),
    "que que": ("ç¡®ç¡®", 1),
    "zhu que": ("å‡†ç¡®", 1),
    "ming que": ("æ˜ç¡®", 1),
    "zhun que": ("å‡†ç¡®", 1),
    "que bao": ("ç¡®ä¿", 1),
    "que fa": ("ç¼ºä¹", 1),
    "que shao": ("ç¼ºå°‘", 1),
    "que shi": ("ç¡®å®", 1),
    "que qie": ("ç¡®åˆ‡", 1),
    "que de": ("ç¼ºå¾·", 1),
    "que xi": ("ç¼ºå¸­", 1),
    "que qin": ("ç¼ºå‹¤", 1),
    "que wei": ("ç¼ºä½", 1),
    "que yi": ("ç¼ºä¸€", 1),

    "xi yue": ("å–œæ‚¦", 1),
    "yin yue": ("éŸ³ä¹", 1),
    "yue ding": ("çº¦å®š", 1),
    "yue du": ("é˜…è¯»", 1),
    "yue er": ("æ‚¦è€³", 1),
    "yue fen": ("æœˆä»½", 1),
    "yue guo": ("è¶Šè¿‡", 1),
    "yue jin": ("è·ƒè¿›", 1),
    "yue jie": ("è¶Šç•Œ", 1),
    "yue lai": ("è¶Šæ¥", 1),
    "yue liang": ("æœˆäº®", 1),
    "yue mu": ("æ‚¦ç›®", 1),
    "yue shu": ("çº¦æŸ", 1),
    "yue yu": ("è¶Šç‹±", 1),
    "yue yue": ("è·ƒè·ƒ", 1),

    "cao": ("è‰", 0),
    "ya": ("å‘€", 0),

    "que": ("å´", 0),
    "yue": ("æœˆ", 0)
}

# input_text = "Ã BÌ Ä† DÌ Ã‰ FÌ Ç´ HÌ Ã JÌ á¸° Ä¹ á¸¾ Åƒ Ã“ PÌ QÌ Å” Åš TÌ Ãš VÌ áº‚ XÌ Ã Å¹" æ‹‰ä¸å¤§å†™å­—æ¯å¸¦é”éŸ³ç¬¦ æŠ‘æ‰¬ç¬¦ ĞĞáªğ”¸ ÄŒ
# input_text = "zhong li xing.Î‘ĞĞáªğ”¸ tai tan dian yan dian zi yan Ğ¡ LStar Å˜97 chong feng qiang dian bi liu dan ke lai bo"
# input_text = "mai chong dao ji su yin shen gou zhua fen shen shuang chong san chong"
# input_text = "li zi lie yan qiang li lang ren jun tuan di wang bei ji xing yang lao fu wu qi"

# Emoji æ˜ å°„è¡¨
emoji_map = {
    "slightly_smiling_face": ":)",
    "smiling_face_with_smiling_eyes": "0v0",
    "grinning_face": ":D",
    "smiling_face_with_hearts": "(^â–½^)",
    "face_with_tears_of_joy": "XD",
    "thinking_face": "(._.)",
    "winking_face": "(^_~)",
    "thumbs_up": "(b^_^)b"
}
chinese_chars = set("ï¼Œã€‚ï¼Ÿï¼ï¼ˆï¼‰ã€ã€‘ã€ï¼›ï¼š") | set(chr(i) for i in range(0x4E00, 0x9FFF))
# å°† è½¬åŒ–ä¸ºASCIIè¡¨æƒ… ä¾‹å¦‚"grinning_face": ":D",

if __name__ == "__main__":
    dag_params = DefaultDagParams()
    # æ£€æµ‹æ–‡ä»¶
    monitor_file()
